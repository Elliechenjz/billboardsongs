min_err_param <- function(model){
min    <- which.min(model$cptable[, "xerror"])
xerror <- model$cptable[min, "xerror"]
return(min)
}
(tree.model, min_err_param)
map_dbl(tree.model, min_err_param)
tree.model[[1]]$cptable[, "xerror"]
tree.model[[1]]$cptable
which.min(tree.model[[1]]$cptable)
tree.model$cptable[,"xerror"]
tree.model[[1]]$cptable[,"xerror"]
tree.model[[1]]$cptable
which.min(tree.model[[1]]$cptable[,"xerror"])
map_dbl(tree.model, optimal_cp_param)
?map_dbl
map_dfr(tree.model, optimal_cp_param)
map_dfc(tree.model, optimal_cp_param)
new <-map_dfc(tree.model, optimal_cp_param)
View(new)
tuning_param
tuning_param %>%
mutate(
cp    = purrr::map_dbl(tree.model, optimal_cp_param)
) %>%
arrange(cp) %>%
top_n(-5, wt = cp)
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 5, by = 1),
maxdepth = seq(from = 5, to = 9, by = 1))
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:5){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
cp <- tree.model[[i]]$cptable[min, "CP"]
xerror <- model$cptable[min, "xerror"]
minlist <- tuning_param$minsplit[i]
maxdepth <- tuning_param$maxdepth[i]
optimal_df <- data.frame(cbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth
))
}
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 5, by = 1),
maxdepth = seq(from = 5, to = 9, by = 1))
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:5){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
cp <- tree.model[[i]]$cptable[min, "CP"]
xerror <- tree.model[[i]]$cptable[min, "xerror"]
minlist <- tuning_param$minsplit[i]
maxdepth <- tuning_param$maxdepth[i]
optimal_df <- data.frame(cbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth
))
}
optimal_df
cbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
optimal_df[i] <- cbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 5, by = 1),
maxdepth = seq(from = 5, to = 9, by = 1))
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:5){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
cp <- tree.model[[i]]$cptable[min, "CP"]
xerror <- tree.model[[i]]$cptable[min, "xerror"]
minlist <- tuning_param$minsplit[i]
maxdepth <- tuning_param$maxdepth[i]
optimal_df[i] <- cbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
}
optimal_df
cbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 5, by = 1),
maxdepth = seq(from = 5, to = 9, by = 1))
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:5){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
cp <- tree.model[[i]]$cptable[min, "CP"]
xerror <- tree.model[[i]]$cptable[min, "xerror"]
minlist <- tuning_param$minsplit[i]
maxdepth <- tuning_param$maxdepth[i]
optimal_df[i,] <- cbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
}
optimal_df <- data.frame()
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 5, by = 1),
maxdepth = seq(from = 5, to = 9, by = 1))
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:5){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
cp <- tree.model[[i]]$cptable[min, "CP"]
xerror <- tree.model[[i]]$cptable[min, "xerror"]
minlist <- tuning_param$minsplit[i]
maxdepth <- tuning_param$maxdepth[i]
optimal_df[i, ] <- cbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
}
View(optimal_df)
optimal_df[i ] <- rbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
rbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
optimal_df[i] <- rbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
optimal_df[,i] <- rbind(
cp = cp, xerror = xerror, minlist = minlist, maxdepth=maxdepth)
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 5, by = 1),
maxdepth = seq(from = 5, to = 9, by = 1))
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:5){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
optimal_df$cp[i] <- tree.model[[i]]$cptable[min, "CP"]
optimal_df$xerror[i] <- tree.model[[i]]$cptable[min, "xerror"]
optimal_df$minlist[i] <- tuning_param$minsplit[i]
optimal_df$maxdepth[i] <- tuning_param$maxdepth[i]
}
optimal_df$minlist
optimal_df$maxdepth
optimal_df$xerror
optimal_df$cp
optimal_df
# Find best tuning parameters that give lowest errors
optimal_df%>%
arrange(-xerror)%>%
top_n(n = 5, wt = xerror)
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 25, by = 1),
maxdepth = seq(from = 5, to = 20, by = 1))
View(tuning_param)
nrow(tuning_param)
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 25, by = 1),
maxdepth = seq(from = 5, to = 20, by = 1))
optimal_df <- data.frame()
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:nrow(tuning_param)){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
optimal_df$cp[i] <- tree.model[[i]]$cptable[min, "CP"]
optimal_df$xerror[i] <- tree.model[[i]]$cptable[min, "xerror"]
optimal_df$minlist[i] <- tuning_param$minsplit[i]
optimal_df$maxdepth[i] <- tuning_param$maxdepth[i]
}
i
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
optimal_df$cp[i] <- tree.model[[i]]$cptable[min, "CP"]
tree.model[[i]]$cptable[min, "CP"]
optimal_df$cp[i]
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 25, by = 1),
maxdepth = seq(from = 5, to = 20, by = 1))
optimal_df <- data.frame(nrow = nrow(tuning_param))
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:nrow(tuning_param)){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
optimal_df$cp[i] <- tree.model[[i]]$cptable[min, "CP"]
optimal_df$xerror[i] <- tree.model[[i]]$cptable[min, "xerror"]
optimal_df$minlist[i] <- tuning_param$minsplit[i]
optimal_df$maxdepth[i] <- tuning_param$maxdepth[i]
}
optimal_df <- data.frame(nrow = nrow(tuning_param), ncol = 4)
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 25, by = 1),
maxdepth = seq(from = 5, to = 20, by = 1))
optimal_df <- data.frame(nrow = nrow(tuning_param), ncol = 4)
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:nrow(tuning_param)){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
optimal_df$cp[i] <- tree.model[[i]]$cptable[min, "CP"]
optimal_df$xerror[i] <- tree.model[[i]]$cptable[min, "xerror"]
optimal_df$minlist[i] <- tuning_param$minsplit[i]
optimal_df$maxdepth[i] <- tuning_param$maxdepth[i]
}
optimal_df
optimal_df <- data.frame()
optimal_df
?data.frame
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:nrow(tuning_param)){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
optimal_df$cp[i] <- tree.model[[i]]$cptable[min, "CP"]
optimal_df$xerror[i] <- tree.model[[i]]$cptable[min, "xerror"]
optimal_df$minlist[i] <- tuning_param$minsplit[i]
optimal_df$maxdepth[i] <- tuning_param$maxdepth[i]
}
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 25, by = 1),
maxdepth = seq(from = 5, to = 20, by = 1))
optimal_df <- data.frame()
optimal_df$cp <- NA
optimal_df$cp <- NA
optimal_df <- data.frame(cp = rep(NA, times = nrow(tuning_param) ))
optimal_df$cp <- NA
# Create a dataframe for minsplit and maxdepth
tuning_param <- expand.grid(
minsplit = seq(from = 1, to = 25, by = 1),
maxdepth = seq(from = 5, to = 20, by = 1))
optimal_df <- data.frame(cp = rep(NA, times = nrow(tuning_param)), xerror = rep(NA, times = nrow(tuning_param)), minsplit = rep(NA, times = nrow(tuning_param)), maxdepth = rep(NA, times = nrow(tuning_param)))
# Empty list to save models
tree.model <- list()
# Loop through models to find the best models
for (i in 1:nrow(tuning_param)){
tree.model[[i]] <- rpart(
count ~ .,bike.train, method  = "anova",
control = list(minsplit = tuning_param$minsplit[i], maxdepth = tuning_param$maxdepth[i])
)
# Get optimal cp parameters
min    <- which.min(tree.model[[i]]$cptable[, "xerror"])
optimal_df$cp[i] <- tree.model[[i]]$cptable[min, "CP"]
optimal_df$xerror[i] <- tree.model[[i]]$cptable[min, "xerror"]
optimal_df$minlist[i] <- tuning_param$minsplit[i]
optimal_df$maxdepth[i] <- tuning_param$maxdepth[i]
}
# Find best tuning parameters that give lowest errors
optimal_df%>%
arrange(-xerror)%>%
top_n(n = 5, wt = xerror)
# Find best tuning parameters that give lowest errors
optimal_df%>%
arrange(-xerror)%>%
top_n(n = -5, wt = xerror)
?rpart.control()
final.tree = rpart(count ~ ., data = bike.train.select,  method = "anova", control=rpart.control(minsplit=1 , cp=0.01, maxdepth = 16,  xval=10))
# Calculate length of tree
nbig.final = length(unique(final.tree$where))
cat('Size of final tree with selected variables: ',nbig.final,'\n')
# Print the cp parameters
cptable.final = printcp(final.tree)
bestcp.final = cptable.final[which.min(cptable.final[,"xerror"]), "CP" ] # optimal cp
paste0("The best cp parameter for selected variables is ", round(bestcp.final, 7))
# Prune the tree to optimal cp parameter
best.tree.final = prune(final.tree, cp=bestcp.final)
paste0("The size of the pruned tree is ", length(unique(best.tree.final$where)))
final.tree = rpart(count ~ ., data = bike.train.select,  method = "anova", control=rpart.control(minsplit=1 , cp=0.0001, maxdepth = 16, xval=10))
# Calculate length of tree
nbig.final = length(unique(final.tree$where))
cat('Size of final tree with selected variables: ',nbig.final,'\n')
# Print the cp parameters
cptable.final = printcp(final.tree)
bestcp.final = cptable.final[which.min(cptable.final[,"xerror"]), "CP" ] # optimal cp
paste0("The best cp parameter for selected variables is ", round(bestcp.final, 7))
# Prune the tree to optimal cp parameter
best.tree.final = prune(final.tree, cp=bestcp.final)
paste0("The size of the pruned tree is ", length(unique(best.tree.final$where)))
cat('Size of final tree with selected variables: ',nbig.final,'\n')
# Calculate length of tree
nbig.final = length(unique(final.tree$where))
length(unique(final.tree$where))
final.tree
final.tree = rpart(count ~ ., data = bike.train.select,  method = "anova", control=rpart.control(minsplit=1 , cp=0.01,  xval=10))
# Calculate length of tree
nbig.final = length(unique(final.tree$where))
cat('Size of final tree with selected variables: ',nbig.final,'\n')
final.tree = rpart(count ~ ., data = bike.train.select,  method = "anova", control=rpart.control(minsplit=10 , cp=0.01,  xval=10))
# Calculate length of tree
nbig.final = length(unique(final.tree$where))
cat('Size of final tree with selected variables: ',nbig.final,'\n')
# Prune the tree to optimal cp parameter
best.tree.sel = prune(select.tree, cp=bestcp.sel)
best.tree.sel
rpart.plot(best.tree.sel)
?rpart
best.tree.sel$frame
head(best.tree.sel$frame)
predict(best.tree.sel)
coef.basic <- predict(best.tree.sel)
?predict
?se
#Save coef and se
coef.basic <- predict(best.tree.sel)
write.csv(coef.basic, "coef.basic.csv")
coef.basic
library(kknn)
install.packages("rhdf5")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.11")
BiocManager::install(version = "3.14")
BiocManager::install("rhdf5")
library(rhdf5)
H5Fopen(file = "/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5")
h5read
h5read(file = "/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5")
?h5read
h5read(file = "/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5", "A")
h5read(file = "/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5",
"TRAAAAW128F429D538")
h5read(file = "/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5",
"A/A/A")
h5read(file = "/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5",
"A")
h5read(file = "/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5",
"a1")
?H5Fopen
df <- H5Fopen(name = "/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5",
"a1")
setwd("/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/A/")
df <- H5Fopen(name = "TRAAAAW128F429D538.h5",
"a1")
df <- H5Fopen(name = "TRAAAAW128F429D538.h5")
View(df)
data.frame(df)
df
df$df
df$metadata
df$analysis
head(df$analysis)
head(df$metadata)
df
head(df$musicbrainz)
df&'analysis'
df&'metadata'
df&'metadata'$songs
df$analysis$analysismetadata
df$analysis$metadata
df$analysis
df&'analysis'
data <- data.frame()
df&'analysis'$bars_confidence
df&'analysis'&bars_confidence
df&'analysis'[1]
df&'analysis'[[1]]
df$analysis
df$analysis[[1]]
df&'analysis'
688/12
df$analysis[[0]]
data$bars_confidence = df$analysis[[1]]
data$bars_start = df$analysis[[2]]
data <- data.frame(nrow = 83)
data$bars_confidence = df$analysis[[1]]
data <- data.frame()
data$bars_confidence = df$analysis[[1]]
data$bars_start = df$analysis[[2]]
data$beats_confidence = df$analysis[[3]]
data$beats_start = df$analysis[[4]]
data$sections_confidence = df$analysis[[5]]
df$analysis[[4]]
df$analysis[[5]]
df$analysis[[6]]
data$segments_loudness_max= df$analysis[[8]]
data$segments_loudness_max_time = df$analysis[[9]]
df&'metadata'
songs <- df$metadata[[5]]
songs
View(songs)
artist_terms_wt <- df$metadata[[3]]
artist_terms_freq <-df$metadata[[2]]
artists_terms <- df$metadata[[1]]
similar_artists <- df$metadata[[4]]
df&'analysis'
bars_confidence = df$analysis[[1]]
bars_start = df$analysis[[2]]
beats_confidence = df$analysis[[3]]
beats_start = df$analysis[[4]]
sections_confidence = df$analysis[[5]]
sections_start = df$analysis[[6]]
segments_confidence = df$analysis[[7]]
segments_loudness_max= df$analysis[[8]]
segments_loudness_max_time = df$analysis[[9]]
segments_loudness_start= df$analysis[[10]]
segments_pitches = df$analysis[[11]]
View(segments_pitches)
segments_start = df$analysis[[12]]
segments_timbre = df$analysis[[13]]
songs= df$analysis[[14]]
tatums_confidence= df$analysis[[15]]
tatums_start= df$analysis[[16]]
songs
df&'metadata'
View(songs)
songs_meta <- df$metadata[[5]]
View(songs_meta)
View(segments_timbre)
View(segments_pitches)
artist_terms_freq
artist_terms
artist_term
artists_terms
View(songs_meta)
View(songs)
tatums_start
segments_start
bars_confidence
df <- H5Fopen(name = "TRAAARJ128F9320760.h5")
head(df$analysis)
head(df$metadata)
df&'analysis'
df&'metadata'
df$analysis[[1]]
data <- data.frame()
bars_confidence = df$analysis[[1]]
bars_start = df$analysis[[2]]
beats_confidence = df$analysis[[3]]
beats_start = df$analysis[[4]]
sections_confidence = df$analysis[[5]]
sections_start = df$analysis[[6]]
segments_confidence = df$analysis[[7]]
segments_loudness_max= df$analysis[[8]]
songs = df$analysis[[14]]
View(songs)
df <- H5Fopen(name = "TRAAAEF128F4273421.h5")
songs = df$analysis[[14]]
songs_meta <- df$metadata[[5]]
View(songs)
View(songs_meta)
songs_full <- data.frame(cbind(songs_meta, songs))
View(songs_full)
View(songs_full)
# This is a sample using the easiest step
setwd("/Users/sahilakudalkar/Library/CloudStorage/OneDrive-TheUniversityofChicago/Documents/Winter 2023/Machine Learning/Final Project/MillionSongSubset/A/A/Z/")
# Read the file
df <- H5Fopen(name = "TRAAZQW128F93430DC.h5")
# This looks useful and should be extracted
songs = df$analysis[[14]]
# This looks useful and should be extracted
songs_meta <- df$metadata[[5]]
# Constructing one row from the data
songs_full <- data.frame(cbind(songs_meta, songs))
View(songs_full)
